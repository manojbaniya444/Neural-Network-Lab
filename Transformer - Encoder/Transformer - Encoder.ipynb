{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOjrOd0QOqgatgjItap6qZq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":77,"metadata":{"id":"xlskILZbrxLD","executionInfo":{"status":"ok","timestamp":1730199583987,"user_tz":-345,"elapsed":674,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[],"source":["from transformers import AutoTokenizer"]},{"cell_type":"code","source":["# !pip install bertviz"],"metadata":{"id":"iplaRm2Mr_W0","executionInfo":{"status":"ok","timestamp":1730199584661,"user_tz":-345,"elapsed":2,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["# bert model visualization library\n","from bertviz.transformers_neuron_view import BertModel\n","from bertviz.neuron_view import show\n","\n","model_checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","\n","text = \"There is a dog in the garden.\"\n","\n","model = BertModel.from_pretrained(model_checkpoint)\n","\n","show(model, \"bert\", tokenizer, text, display_mode = \"light\", layer = 0, head = 0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505,"output_embedded_package_id":"1iTXWHIbItfT4QKNi0vky7H71QNPfMGBh"},"id":"l1-hiUmWsBYV","executionInfo":{"status":"ok","timestamp":1730199600635,"user_tz":-345,"elapsed":15976,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"e1820f49-de76-43d8-8961-9010f602ca89"},"execution_count":79,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Tokenization"],"metadata":{"id":"A7Os4HrjtgNh"}},{"cell_type":"code","source":["tokenized_text = tokenizer(text, return_tensors = \"pt\")\n","tokenized_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-U6JnBvtjMc","executionInfo":{"status":"ok","timestamp":1730199600635,"user_tz":-345,"elapsed":19,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"efdc26ea-280b-4ede-8450-b29fd3aa7406"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[ 101, 2045, 2003, 1037, 3899, 1999, 1996, 3871, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["tokenized_text.input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWkkMwjNuI9y","executionInfo":{"status":"ok","timestamp":1730199600635,"user_tz":-345,"elapsed":16,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"7942582d-19ff-4486-ddfd-10c9b1a79aca"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 101, 2045, 2003, 1037, 3899, 1999, 1996, 3871, 1012,  102]])"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["from transformers import AutoConfig\n","\n","config = AutoConfig.from_pretrained(model_checkpoint)\n","config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qsyDk5quSeO","executionInfo":{"status":"ok","timestamp":1730199600635,"user_tz":-345,"elapsed":13,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"3bab7c30-a6f7-4bb0-a2a5-39fff42965a5"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}"]},"metadata":{},"execution_count":82}]},{"cell_type":"markdown","source":["# Embedding"],"metadata":{"id":"XASkjigduvOt"}},{"cell_type":"code","source":["import torch\n","\n","token_embedding = torch.nn.Embedding(config.vocab_size, config.hidden_size)\n","token_embedding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jz6zvoX1uwr8","executionInfo":{"status":"ok","timestamp":1730199600636,"user_tz":-345,"elapsed":12,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"0c0adbe9-edfb-49f0-f4ee-b0b7594b3459"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(30522, 768)"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["inputs_embeds = token_embedding(tokenized_text.input_ids)\n","inputs_embeds.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywwHJj_PvTIQ","executionInfo":{"status":"ok","timestamp":1730199600636,"user_tz":-345,"elapsed":9,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"7b289a15-6766-4078-e021-c44f44a3330d"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["inputs_embeds[0][0].shape\n","# this is the embedding for the first word of the first sentence in out input"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YL5whWN_vd9n","executionInfo":{"status":"ok","timestamp":1730199600636,"user_tz":-345,"elapsed":8,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"03fd3965-a575-40ee-d76b-d695336f2e1b"},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([768])"]},"metadata":{},"execution_count":85}]},{"cell_type":"markdown","source":["# Attention"],"metadata":{"id":"9oEoEWvXv6vh"}},{"cell_type":"code","source":["import torch\n","from math import sqrt\n","import numpy as np"],"metadata":{"id":"FSmLag9lv8eM","executionInfo":{"status":"ok","timestamp":1730199601339,"user_tz":-345,"elapsed":708,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["query = key = value = inputs_embeds # set the Q, K and V to the same as inouts_embeds later they can update through training"],"metadata":{"id":"ACExEZZGwAg7","executionInfo":{"status":"ok","timestamp":1730199601340,"user_tz":-345,"elapsed":20,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["key.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRm5lUjxwJd7","executionInfo":{"status":"ok","timestamp":1730199601340,"user_tz":-345,"elapsed":20,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"8830dcb9-7697-49cb-851e-8e5199734410"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["dim_k = key.size(-1) # get 768 as dimension\n","print(\"The dimension for the vector is: \", dim_k)\n","\n","attn_scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k) # batch multiplcation\n","print(\"The attention score for the input: \", attn_scores) # this the attention score for our token of 10 input\n","print(\"Shape of attention score: \", attn_scores.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-3ZInIHwVn5","executionInfo":{"status":"ok","timestamp":1730199601340,"user_tz":-345,"elapsed":19,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"3e121f29-3bf1-4fd7-9284-3e087477b5e0"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["The dimension for the vector is:  768\n","The attention score for the input:  tensor([[[ 2.7089e+01, -4.9855e-01, -7.0206e-01,  1.2510e+00,  9.5965e-01,\n","          -1.0770e+00, -7.0859e-01, -5.0018e-01, -3.4626e-01, -6.0123e-03],\n","         [-4.9855e-01,  2.7518e+01, -2.5033e-02,  1.6455e+00, -5.9037e-01,\n","          -6.3501e-01, -1.1600e+00, -8.8539e-01,  4.2317e-01,  9.4370e-02],\n","         [-7.0206e-01, -2.5033e-02,  2.5871e+01,  1.0656e+00, -1.1591e+00,\n","          -4.8743e-01, -8.2665e-01, -1.1937e+00, -1.8482e-01,  8.6857e-01],\n","         [ 1.2510e+00,  1.6455e+00,  1.0656e+00,  3.2572e+01, -1.7993e+00,\n","           9.1329e-01, -1.3535e+00,  1.9169e-01, -1.8282e+00, -1.5603e+00],\n","         [ 9.5965e-01, -5.9037e-01, -1.1591e+00, -1.7993e+00,  2.8650e+01,\n","           5.7000e-01, -5.2806e-01, -8.3222e-01,  5.7307e-01, -7.3861e-01],\n","         [-1.0770e+00, -6.3501e-01, -4.8743e-01,  9.1329e-01,  5.7000e-01,\n","           3.0560e+01, -9.9571e-01, -1.6467e-01,  4.5263e-01,  8.2892e-01],\n","         [-7.0859e-01, -1.1600e+00, -8.2665e-01, -1.3535e+00, -5.2806e-01,\n","          -9.9571e-01,  2.6797e+01,  6.1188e-02,  1.7659e+00, -1.5761e+00],\n","         [-5.0018e-01, -8.8539e-01, -1.1937e+00,  1.9169e-01, -8.3222e-01,\n","          -1.6467e-01,  6.1188e-02,  2.4791e+01,  3.3759e-01, -3.1969e-01],\n","         [-3.4626e-01,  4.2317e-01, -1.8482e-01, -1.8282e+00,  5.7307e-01,\n","           4.5263e-01,  1.7659e+00,  3.3759e-01,  2.7281e+01,  9.4317e-01],\n","         [-6.0123e-03,  9.4370e-02,  8.6857e-01, -1.5603e+00, -7.3861e-01,\n","           8.2892e-01, -1.5761e+00, -3.1969e-01,  9.4317e-01,  2.9638e+01]]],\n","       grad_fn=<DivBackward0>)\n","Shape of attention score:  torch.Size([1, 10, 10])\n"]}]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","weights = F.softmax(attn_scores, dim=1) # attention weights\n","print(\"Shape of weight: \", weights.shape)\n","weights.sum(dim=-1) # checking the softmax output because they need to sum up to 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXdupZrzxb96","executionInfo":{"status":"ok","timestamp":1730199601340,"user_tz":-345,"elapsed":16,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"046fb1d6-e23b-4261-b1d1-516cdb6fc683"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of weight:  torch.Size([1, 10, 10])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=<SumBackward1>)"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["attention_outputs = torch.bmm(weights, value)\n","attention_outputs.shape # final self attention output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ihrGDkWxrdt","executionInfo":{"status":"ok","timestamp":1730199601340,"user_tz":-345,"elapsed":14,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"a0d060b0-f7be-428b-abc5-432152c83982"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":91}]},{"cell_type":"markdown","source":["# Modular: Scaled dot product attention"],"metadata":{"id":"Q1vKhoX6yq2t"}},{"cell_type":"code","source":["def scaled_dot_product_attention(query, key, value):\n","  \"\"\"\n","  Takes the Q,K,V matrix and returns the attention output\n","  \"\"\"\n","  dim_k = key.size(-1)\n","  attention_scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n","  attention_weights = F.softmax(attention_scores, dim=-1)\n","  attention_outputs = torch.bmm(attention_weights, value)\n","  return attention_outputs"],"metadata":{"id":"oXV86t6QyuIo","executionInfo":{"status":"ok","timestamp":1730199601340,"user_tz":-345,"elapsed":13,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["scaled_dot_product_attention(query, key, value).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BsIf45cfzhCJ","executionInfo":{"status":"ok","timestamp":1730199601340,"user_tz":-345,"elapsed":13,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ae93c639-009e-42ee-feae-3a2bb0c6793a"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":93}]},{"cell_type":"markdown","source":["In paper they use multi head attention to capture different meaning parallely."],"metadata":{"id":"gUBuk88d2I_1"}},{"cell_type":"markdown","source":["# Multi-head Attention Mechanism"],"metadata":{"id":"dzMR42rI0Bwc"}},{"cell_type":"code","source":["query.shape # 1 , 10 token , 768 embedding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7h4QPz9c0epn","executionInfo":{"status":"ok","timestamp":1730199601340,"user_tz":-345,"elapsed":12,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"4f5c4376-415f-4d1f-bf1d-b4441f7db8a5"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["import torch\n","\n","class AttentionHead(torch.nn.Module):\n","  def __init__(self, embed_dim, head_dim):\n","    super().__init__()\n","    self.q = torch.nn.Linear(in_features=embed_dim, out_features=head_dim)\n","    self.k = torch.nn.Linear(in_features=embed_dim, out_features=head_dim)\n","    self.v = torch.nn.Linear(in_features=embed_dim, out_features=head_dim)\n","\n","  def forward(self, hidden_state):\n","    attention_outputs = scaled_dot_product_attention(\n","        self.q(hidden_state),\n","        self.k(hidden_state),\n","        self.v(hidden_state)\n","    )\n","    return attention_outputs"],"metadata":{"id":"i37NoJS60EeV","executionInfo":{"status":"ok","timestamp":1730199601340,"user_tz":-345,"elapsed":11,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["bert_embed_dim = 768\n","bert_head_dim = 12\n","\n","bert_embed_dim / bert_head_dim\n","# 64 which is the linear projection of each attention head in multi head attention\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PG7fEf0L1wze","executionInfo":{"status":"ok","timestamp":1730199601341,"user_tz":-345,"elapsed":12,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"7e5c3a20-bebf-4bd9-e3c0-acecc9bb19d5"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64.0"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gHWycSq2puw","executionInfo":{"status":"ok","timestamp":1730199601341,"user_tz":-345,"elapsed":10,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"89abc840-82cc-47ed-9b30-e82ecb404588"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["class MultiHeadAttention(torch.nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    embed_dim = config.hidden_size\n","    num_heads = config.num_attention_heads\n","    head_dim = embed_dim // num_heads # number of multiheads in model\n","\n","    self.heads = torch.nn.ModuleList( # list with gradient associated in it\n","      [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n","    )\n","    self.output_linear = torch.nn.Linear(\n","        in_features=embed_dim, # embed_dim * head_dim ?\n","        out_features=embed_dim\n","    )\n","  def forward(self, hidden_state):\n","    concatenated_outputs = torch.cat(\n","        [h(hidden_state) for h in self.heads], dim=-1\n","    )\n","    concatenated_outputs = self.output_linear(concatenated_outputs)\n","    return concatenated_outputs"],"metadata":{"id":"KZJDnrV635OL","executionInfo":{"status":"ok","timestamp":1730199869668,"user_tz":-345,"elapsed":2,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["inputs_embeds.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VS5cWBpc58_9","executionInfo":{"status":"ok","timestamp":1730199871921,"user_tz":-345,"elapsed":2,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ec84a12f-18d9-4292-842f-70db645fb527"},"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["# check the attention code\n","multihead_attention = MultiHeadAttention(config)\n","attention_output = multihead_attention(inputs_embeds)\n","attention_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGkwQR1s5uZt","executionInfo":{"status":"ok","timestamp":1730199874090,"user_tz":-345,"elapsed":4,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"6b0e1e06-013d-41dd-90fe-a02d392e1c5a"},"execution_count":104,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":104}]},{"cell_type":"markdown","source":["# Visualize Attention of Our Attention Code"],"metadata":{"id":"Glylbla39Pno"}},{"cell_type":"code","source":["from bertviz import head_view\n","\n","from transformers import AutoModel\n","\n","model = AutoModel.from_pretrained(model_checkpoint, output_attentions=True)\n","\n","sentence_a = \"There is a dog in the garden.\"\n","sentence_b = \"The dog is in the garden.\""],"metadata":{"id":"3E3RGVmm9T2X","executionInfo":{"status":"ok","timestamp":1730200215715,"user_tz":-345,"elapsed":685,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["viz_inputs = tokenizer(sentence_a, sentence_b, return_tensors=\"pt\")"],"metadata":{"id":"ioJAHYPK96ZF","executionInfo":{"status":"ok","timestamp":1730200306025,"user_tz":-345,"elapsed":1547,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["viz_inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"avsI5a9v-P2h","executionInfo":{"status":"ok","timestamp":1730200312346,"user_tz":-345,"elapsed":652,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"d281e5bd-884a-4a76-c425-2aaae250b44b"},"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[ 101, 2045, 2003, 1037, 3899, 1999, 1996, 3871, 1012,  102, 1996, 3899,\n","         2003, 1999, 1996, 3871, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":["attention = model(**viz_inputs).attentions"],"metadata":{"id":"87zt9I-6-k_y","executionInfo":{"status":"ok","timestamp":1730200453600,"user_tz":-345,"elapsed":1,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":116,"outputs":[]},{"cell_type":"code","source":["sentence_b_start = (viz_inputs.token_type_ids == 0).sum(dim=1)\n","sentence_a_end = (viz_inputs.token_type_ids == 1).sum(dim=1)\n","\n","tokens = tokenizer.convert_ids_to_tokens(viz_inputs.input_ids[0])\n","\n","head_view(attention, tokens, sentence_b_start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475,"output_embedded_package_id":"1fnzuHkNWyPSeZYUcOD0FnVhMV1cbEr1h"},"id":"JYWrPmMY-oZO","executionInfo":{"status":"ok","timestamp":1730200545800,"user_tz":-345,"elapsed":12887,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"7698e016-d9bf-48e6-87bf-3f02e90461c6"},"execution_count":119,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Position wise Feed Forward Layer"],"metadata":{"id":"slhIG41Y_yeX"}},{"cell_type":"code","source":["class FeedForward(torch.nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    self.linear_1 = torch.nn.Linear(\n","        in_features=config.hidden_size,\n","        out_features=config.intermediate_size\n","    )\n","    self.linear_2 = torch.nn.Linear(\n","        in_features=config.intermediate_size,\n","        out_features=config.hidden_size\n","    )\n","    self.gelu = torch.nn.GELU()\n","    self.dropout = torch.nn.Dropout(\n","        config.hidden_dropout_prob\n","    )\n","\n","  def forward(self, x):\n","    x = self.linear_1(x)\n","    x = self.gelu(x)\n","    x = self.linear_2(x)\n","    x = self.dropout(x)\n","    return x"],"metadata":{"id":"EjS97QzuAQbe","executionInfo":{"status":"ok","timestamp":1730201124001,"user_tz":-345,"elapsed":628,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["attention_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5EDGPb4DBgfE","executionInfo":{"status":"ok","timestamp":1730201130314,"user_tz":-345,"elapsed":3,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ea3966d5-0389-4195-fc21-27e60c96b6fc"},"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["feed_forward = FeedForward(config)\n","ff_output = feed_forward(attention_output)\n","ff_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ok4URuEL__b_","executionInfo":{"status":"ok","timestamp":1730201132064,"user_tz":-345,"elapsed":912,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"fda7713a-f182-43d3-bc2f-1d572b51552b"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":123}]},{"cell_type":"markdown","source":["# Layer Norm"],"metadata":{"id":"CrA9OgPgByF9"}},{"cell_type":"code","source":["inputs_embeds.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0TWedHaCOOh","executionInfo":{"status":"ok","timestamp":1730201451660,"user_tz":-345,"elapsed":698,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ffee954b-79ab-46b6-a179-62e980ad8c9d"},"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":127}]},{"cell_type":"code","source":["class TransformerEncoderLayer(torch.nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    self.layer_norm_1 = torch.nn.LayerNorm(config.hidden_size)\n","    self.layer_norm_2 = torch.nn.LayerNorm(config.hidden_size)\n","\n","    self.attention = MultiHeadAttention(config)\n","\n","    self.feed_forward = FeedForward(config)\n","\n","  def forward(self, x):\n","    hidden_state = self.layer_norm_1(x)\n","    x = x + self.attention(hidden_state)\n","    x = x + self.feed_forward(self.layer_norm_2(x))\n","    return x"],"metadata":{"id":"1XdYpV7QB0fO","executionInfo":{"status":"ok","timestamp":1730201394279,"user_tz":-345,"elapsed":2,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["encoder_layer = TransformerEncoderLayer(config)\n","encoder_layer(inputs_embeds).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13LQayYQCht9","executionInfo":{"status":"ok","timestamp":1730201476437,"user_tz":-345,"elapsed":911,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"f345be38-5763-41da-cd20-c1d175cf916d"},"execution_count":128,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":128}]},{"cell_type":"markdown","source":["# Positional Encoding"],"metadata":{"id":"C6ud62M8C_wt"}},{"cell_type":"code","source":["class Embeddings(torch.nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    self.token_embeddings = torch.nn.Embedding(config.vocab_size, config.hidden_size)\n","    self.position_embeddings = torch.nn.Embedding(config.max_position_embeddings, config.hidden_size)\n","    self.layer_norm = torch.nn.LayerNorm(config.hidden_size, eps=1e-12)\n","    self.dropout = torch.nn.Dropout()\n","\n","  def forward(self, input_ids):\n","    seq_length = input_ids.size(1)\n","    position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n","    token_embeddings = self.token_embeddings(input_ids)\n","    position_embeddings = self.position_embeddings(position_ids)\n","\n","    embeddings = token_embeddings + position_embeddings\n","    embeddings = self.layer_norm(embeddings)\n","    embeddings = self.dropout(embeddings)\n","    return embeddings"],"metadata":{"id":"PXVIBXO9DBun","executionInfo":{"status":"ok","timestamp":1730202048002,"user_tz":-345,"elapsed":629,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["embedding_layer = Embeddings(config)\n","embedding_layer(viz_inputs.input_ids).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2CbiTHfE3Rq","executionInfo":{"status":"ok","timestamp":1730202051431,"user_tz":-345,"elapsed":632,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"a05af723-bc12-4a9d-c06b-173fbf673a48"},"execution_count":134,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 18, 768])"]},"metadata":{},"execution_count":134}]},{"cell_type":"code","source":["viz_inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rl5x1OY4FGqZ","executionInfo":{"status":"ok","timestamp":1730202079097,"user_tz":-345,"elapsed":3,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"94416fb4-66e7-4680-930b-7a8876c4aa57"},"execution_count":135,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[ 101, 2045, 2003, 1037, 3899, 1999, 1996, 3871, 1012,  102, 1996, 3899,\n","         2003, 1999, 1996, 3871, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":135}]},{"cell_type":"markdown","source":["# Encoder Architecture"],"metadata":{"id":"4vjq_8mlFK0M"}},{"cell_type":"code","source":["class TransformerEncoder(torch.nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    self.embeddings = Embeddings(config)\n","    self.layers = torch.nn.ModuleList(\n","        [TransformerEncoderLayer(config) for _ in range(config.num_hidden_layers)]\n","    )\n","\n","  def forward(self, x):\n","    x = self.embeddings(x)\n","    for layer in self.layers:\n","      x = layer(x)\n","    return x"],"metadata":{"id":"X2v7XNl8FM8S","executionInfo":{"status":"ok","timestamp":1730202213955,"user_tz":-345,"elapsed":637,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["tokenized_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iapVTVZ_FzTT","executionInfo":{"status":"ok","timestamp":1730202257614,"user_tz":-345,"elapsed":625,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ca4d2e38-eae5-42e2-b0df-7a086387979b"},"execution_count":137,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[ 101, 2045, 2003, 1037, 3899, 1999, 1996, 3871, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":137}]},{"cell_type":"code","source":["TransformerEncoder(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RR0o5VLwF1n1","executionInfo":{"status":"ok","timestamp":1730202283136,"user_tz":-345,"elapsed":3088,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"db8a5dde-5685-4863-8cd2-ff7d066d8304"},"execution_count":139,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TransformerEncoder(\n","  (embeddings): Embeddings(\n","    (token_embeddings): Embedding(30522, 768)\n","    (position_embeddings): Embedding(512, 768)\n","    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (layers): ModuleList(\n","    (0-11): 12 x TransformerEncoderLayer(\n","      (layer_norm_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layer_norm_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (attention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-11): 12 x AttentionHead(\n","            (q): Linear(in_features=768, out_features=64, bias=True)\n","            (k): Linear(in_features=768, out_features=64, bias=True)\n","            (v): Linear(in_features=768, out_features=64, bias=True)\n","          )\n","        )\n","        (output_linear): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (feed_forward): FeedForward(\n","        (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n","        (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n","        (gelu): GELU(approximate='none')\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":139}]},{"cell_type":"code","source":["encoder = TransformerEncoder(config)\n","output = encoder(tokenized_text.input_ids)"],"metadata":{"id":"gQVJGIrMFpoY","executionInfo":{"status":"ok","timestamp":1730202267469,"user_tz":-345,"elapsed":4374,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["output.shape, tokenized_text.input_ids.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CavRIJ3kF7ym","executionInfo":{"status":"ok","timestamp":1730202358319,"user_tz":-345,"elapsed":3,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"e0b26268-22da-4745-a562-a48123dfc339"},"execution_count":142,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 10, 768]), torch.Size([1, 10]))"]},"metadata":{},"execution_count":142}]},{"cell_type":"markdown","source":["# Classification head: for classification"],"metadata":{"id":"gxP-4FOrGoPE"}},{"cell_type":"code","source":["config.hidden_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5q2MlBzHgnO","executionInfo":{"status":"ok","timestamp":1730202708460,"user_tz":-345,"elapsed":4,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"0e8165c1-937f-4f92-ea34-a32f4c21c08c"},"execution_count":143,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{},"execution_count":143}]},{"cell_type":"code","source":["class TransformerForSequenceClassification(torch.nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    self.encoder = TransformerEncoder(config)\n","    self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n","    self.classifier = torch.nn.Linear(config.hidden_size, config.num_labels) # get 768 input feature from [CLS] token and return required output label\n","\n","  def forward(self, x):\n","    x = self.encoder(x)[:, 0, :] # [CLS] token only taken for classification of sequence [10, 768]\n","    x = self.dropout(x)\n","    x = self.classifier(x)\n","    return x"],"metadata":{"id":"6_7ksD-rGsIP","executionInfo":{"status":"ok","timestamp":1730202750394,"user_tz":-345,"elapsed":684,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["config.num_labels = 3 # for 3 class\n","config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1b6LkNRGkf3","executionInfo":{"status":"ok","timestamp":1730202769646,"user_tz":-345,"elapsed":763,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"60741ed0-f9f5-46e1-9d93-121164eb7e49"},"execution_count":145,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","source":["encoder_classifier = TransformerForSequenceClassification(config)\n","classifier_preds = encoder_classifier(tokenized_text.input_ids)"],"metadata":{"id":"6V4Jj_NeHxVM","executionInfo":{"status":"ok","timestamp":1730202803983,"user_tz":-345,"elapsed":5786,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":147,"outputs":[]},{"cell_type":"code","source":["classifier_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERFaSAUiH5N4","executionInfo":{"status":"ok","timestamp":1730202809147,"user_tz":-345,"elapsed":1087,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"a3491ce8-8f90-4541-8ae3-d7566cbf7fa0"},"execution_count":148,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3806, -1.7427,  2.6048]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":148}]}]}